---
layout:     post
title:      降维：PCA(Principal component analysis)
subtitle:   几何角度、概率角度
date:       2020-05-04
author:     LT
header-img: 
catalog: true
tags:
    - 机器学习
    - 
---

### 一、背景
1. 维度灾难👉数据稀疏性
2. 过拟合（训练误差小，泛化误差大）的解决方法
    - 增加数据
    - 正则化
    - 降维
        + 直接降维👉特征选择
        + 线性降维👉PCA，MDS
        + 非线性降维👉流形

### 二、几何角度：PCA(Principal component analysis)
1. 一个中心
    - 原始特征空间重构：相关👉无关
2. 两个基本点（同一个意思，都是为中心服务的）
    - 最大投影方差
    - 最小重构距离
3. 最大投影方差
    - 找到主成分（一组线性无关的正交基/坐标轴）
    - 步骤
        + 中心化/标准化：$x_i- \bar x$
        + 先看一个点。
            * 加入找到的主成分是$u_1$。$u_1$的模是1。
            * $x_i$在$u_1$上的投影就是$J=(x_i- \bar x)^T u_1$
            * 所以N个点的投影方差是$ J= \frac{1}{N} \sum_{i=1}^{N} ( (x_i- \bar x)^T u_1 )^2 \\ = u_1^T S u_1$，其中$u_1$的模是1，S是样本方差。
            * $ \hat u_1= arg max J $，其中$u_1$的模是1。可以用拉格朗日乘子法求解，即$ Su_1= λ_1 u_1 $。(λ是特征值)
    - 步骤小结：
        + 特征重构，找到$u_1,...u_p$，分别对应的是$λ_1,...,λ_p$。（x是p维）
        + 筛选前q个主成分u。

4. 最小重构代价/距离
    - 如果保留p个主成分$u_1,...u_p$，把它们看作`坐标轴`来表示（重构）x，就是$ x_i= \sum_{k=1}^{p} (x_i^T u_k)u_k $
        * 注，这里$x_i$看作中心化/标准化之后的：$x_i- \bar x$
    - 实际上，我们做了降维（保留前q个主成分u），所以重构的x其实是$ \hat x_i= \sum_{k=1}^{q} (x_i^T u_k)u_k $
        
    - 所以，重构代价是$ J= \frac{1}{N} \sum_{i=1}^{N} (x_i- \hat x_i)^2 \\ = \sum_{k=q+1}^{p} u_k^T S u_k $
        * $ u_k= arg min \sum_{q+1}^{p} u_k^T S u_k $
        * 其中，$u_k$的模是1，q < p


### 三、概率角度看PCA：p-PCA
1. p-PCA，符号表示
    - $ x \in R^p, z \in R^q $
    - 其中，x是观测数据（observed data），z是隐变量（latent variable），`q < p`。
    - $ z \sim N(0_q, I_q) \\
        x= wz +μ + ε \\
        ε \sim N(0, σ^2 I_p) $
    - 以上方程组可看作Linear Gaussian Model，由于分布构造形式简单，[z, x|z, x, z|x](./2020-05-01-频率-贝叶斯.md)都可以计算出来。

2. p-PCA可以解决的两个问题
    - 推断：p(z|x)
    - 学习：w，μ，σ²👉如果MLE不好求就用EM
3. p-PCA和GMM区别
    - p-PCA 连续
    - GMM 离散


### 对比
1. Diffeomorphism(微分同胚)：
    - 一个映射，如果正变换和逆变换都是光滑的（有连续偏导），则称该映射是Diffeomorphism
2. PCA，ICA(independent component analysis)区别
    - PCA：特征提取，降维。（用于预处理）
    - ICA：认为观测信号是若干个统计`独立`的分量的`线性组合`。（比如解混响）
3. PCA，线性判别分析(LDA, Linear Discriminant Analysis)思想有点像。不同之处是，
    - PCA用于降维/特征提取
    - LDA用于线性分类中的硬分类
