---
layout:     post
title:      GAN基础
subtitle:   理论推导
date:       2019-05-27
author:     LT
header-img: 
catalog: true
# mathjax: true
tags:
    - GAN
    - 深度学习
    - 理论篇
---


>参考
>>[课程视频](https://www.bilibili.com/video/BV1Up411R7Lk)
>>与GAN有关的PPT课件、视频、作业要求，参见[李宏毅-课程主页](http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html)
>>[课程笔记](http://www.gwylab.com/note-gans.html)
>>[GAN综述-2020](https://mp.weixin.qq.com/s/iLAE_WR-rQrqd4dtYWB_gA)


### 一，Introduction
#### Basic idea（1）
+ G generator：只学习细节，不知道全局
如果单独使用G来生成图像，VAE（variational auto-encoder）中的decoder就是我们想要的G。
VAE的过程是：**input image**---encoder--->**code**---decoder--->**output image**
但是这里的G有个问题：只学习细节，不知道全局（比如像素之间的相关性）。that's to say,采用模型中的解码端作为G，本质是在生成训练集已有的数据类似的数据，无法生成训练集中没有的数据。

+ D discriminator：
只学习全局，不知道细节。
只有positive example，没有negative example。
如果单独使用D来生成图像（穷举所有的pixel？），那么不管生成什么样的图像，都会被认为是positive example。

+ 将G和D结合起来->GAN
实验证明，GAN生成的图像质量比VAE要好。


#### Basic idea（2）
Pdata是真实数据的分布，PG是生成数据的分布。G是生成网络Generator，D是判别网络Discriminator。开山作[paper](https://arxiv.org/abs/1406.2661)中的value function V(D, G)定义如下。（可以理解为PG和Pdata之间的divergence）

$
V(D, G) = E_{ x \sim p_{data}(x)} \log D(x)+ E_{z \sim p_z(z)}  \log (1-D(G(z))) 
$

$ D ^* = \max_D V(D, G) $

$ G ^* = \min _G D ^* $
$      = \min _G E_{z \sim p_z(z)}\log (1-D(G(z))) $
$      = \max _G E_{z \sim p_z(z)}\log D(G(z)) $

步骤：
1. 初始化G和D的相关参数
2. 先fix G 训练Discriminator，使得divergence越大越好(便于分类)；
3. 再fix D(此时V(D, G)中的第一项是常数，计算时无需考虑了)训练Generator，使得divergence越小越好。

#### Discriminator与binary classifier
1. V(D, G)可以看作`正例`真实数据x(cover)和`反例`生成数据G_z(stego)之间的差距。
（多一个负号就是交叉熵）
2. D其实就是一个二分类器(可以是使用了sigmoid作为输出的深层网络)，来自Pdata的x是正例，label=1；来自PG的x'=G_z是反例，label=0。



### 二，Theory
1. GAN的思想是，generator`最小化`生成数据和真实数据之间的Div，而discriminator想要`最大化`Div。[了解更多](https://leeeliu.github.io/2020/04/10/MLE和GAN和flow/)
2. 从generator角度来看，$ G^{*} = arg  \min_{G} Div(P_{G},P_{data}) $ （式2）。这个Div其实是JS-Div，下文细说。
3. 怎样衡量这个$Div(P_{G},P_{data})$？
    - **让D来衡量Div**。
    我们虽然不知道$P_{data}$和$P_{G}$，但是可以从这两个分布里sample，把真实数据和生成数据喂给discriminator D。
    - **理论上，D量出来的Div是JS-Div**。
        * 把D想要`最大化`的目标V写成期望形式:

        $$ V = E_{x \sim P_{data}}[log D(x)] + E_{x \sim P_{G}}[log (1-D(x))] $$

        * 对x积分，把积分里面的每个项拿出来：

        $$ V = P_{data}(x)logD(x) + P_{G}(x)log[1-D(x)] $$

        * 要想求V的极大值，我们对让V对D的偏导数=0。算得

        $$ D^{*}= \frac{P_{data}}{P_{data}+P_{G}} $$。

        把$D^{*}$代入V中，发现此时的V，就是$P_{data}$和$P_{G}$的JS-divergence。
    - **实践上，V的表示，用sample来代替期望**。用V替换式2里的Div即可。

    $$V^{\sim}= \frac{1}{m} \sum_{i=1}^{m}[log D(x)+log(1-D(G_z))] $$
    
4. 两个问题
    - Discriminator能衡量data和G(z)的Div吗？
        * 证据1
        有些人用GAN做pre-training，训好的D直接拿来用。说明D没有烂掉。
        * 证据2
        如果D想衡量data和G(z)的Div，那么，用前一次的D（基于前一次G）来初始化下一个D的参数，这样就不太对。现在的G已经变了，我要以前的D有何用？然而事实证明，这样做有用。（可能因为，G改变很小）。
    - D可以最大化JS-Div。那么，G真的是在最小化JS-Div吗？答曰：理论上不是。实践中，采取一些训练手段，假设它是。
        * 例子：G1更新为G2。如果G2与G1差距太大，那么G2最小化的就不是JS-Div。![](https://img-1300025586.cos.ap-shanghai.myqcloud.com/G1toG2.png)
        * 所以，训练手段是，D训练快一些，G训练慢一些。（理论上，每次重新训练D，train到底。达到极大值的V，才是JS-Div，才能给G）。