---
layout:     post
title:      Closed-Form Factorization of Latent Semantics in GANs
subtitle:   生成模型（GAN）潜在空间-语义解释性
date:       2020-07-31
author:     LT
header-img: 
catalog: true
tags:
    - GAN
    - 深度学习
    - 计算机视觉
---

## Closed-Form Factorization of Latent Semantics in GANs

### 论文简介
1. 题目《Closed-Form Factorization of Latent Semantics in GANs》，用于`无监督`条件下GAN潜在语义识别。
1. 作者：Yujun Shen, Bolei Zhou 周博磊团队
1. 单位：The Chinese University of Hong Kong 港中文
1. 发表状态：preprint，源码地址公开但是未上传
2. [项目地址](https://genforce.github.io/sefa/)
3. [Demo视频](https://v.qq.com/x/page/f3120a6rj5m.html)
    ![GIF](https://genforce.github.io/sefa/assets/teaser.gif)


### 背景
1. 合成图像时，研究GAN潜在空间里的语义解释性，是有应用价值的。
    - 近期研究表明，在学习合成图像时，GAN会自发地在潜在空间中表示出多种可解释属性，如用于人脸合成的性别特征、用于场景合成的光照条件。(无条件GAN在中间特征映射、初始潜在空间中，自动编码各种语义)
    - 通过正确识别这些语义，将GAN学习到的知识重新利用，合理地控制图像生成过程，从而实现图像编辑的广泛应用，如人脸操纵和场景编辑。
2. 直观思路
    - 解释GAN潜在空间的关键是，找到与人类可理解属性相对应的子空间。
    - 将潜码（latent code）向特定子空间的方向移动，对应地改变合成图像的语义。
    
### 挑战
3. 然而，由于潜在空间的`高维`性以及图像`语义的多样性`，在潜在空间中寻找`有效方向`是极具挑战性的。
### 现有方法、局限性    
4. 现有的`监督学习`方法是这样做的
    - 三步骤：采样、标注和边界搜索。
    - 先随机抽取大量潜码，合成一组图像，并使用一些预定义标签进行图像标注（分配语义分数，使用图像得分pairs，进行有监督的语义搜索）利用这些标注样本学习潜在空间中的分离边界（separation boundary）。
    - 要想得到训练该边界的标签，要么引入预训练语义预测器，要么利用图像的一些简单统计信息（比如物体位置、颜色色调）。
5. 现有方法的局限性
    - (1)**有监督**：严重依赖于`预定义的语义`和`标注样本`。
        + 当语义预测器丢失时，识别不出预定义之外的语义，多样性差。
    - (2)依赖于**大量数据抽样**。一些并行工作也研究了GAN的无监督语义发现。但是它们都基于大量数据的抽样。
        + 采样不稳定，不同的合成集合，可能导致不同的边界搜索，为了确定一些罕见的属性，必须生成大量的样本，以确保为边界训练收集足够的positive examples，这是相当耗时和biased的。
        
### 针对2个局限性，本文方法是
1. `独立于抽样`
    - 提出`封闭形式因式分解`(closed-form factorization)方法**SeFa**，独立于抽样。
2. `无监督`，解释GAN潜在语义
    - 不再将`样本合成`作为中间步骤，而是通过`直接`探索GAN的生成机制，来解释内部表征。
        + GAN的第一层通常是一个全连接层FC，将潜码输入到生成器，FC提供了将潜在空间投影到变换空间（transformed space）的驱动力。
        + **这种变换过滤了潜在空间中一些不重要的方向，从而突出了图像合成的关键方向**。能够`识别这些重要的潜在方向`，就能控制图像生成过程，`编辑合成图像的语义`。
    - SeFa只需使用GAN学得的`权重`进行语义发现。不需任何先验监督信息（例如语义标签或分类器）。


### 回顾-摘要
1. 要解决的问题
    - 目标：在图像合成GAN的潜在空间中,识别语义.
    - 由于现有方法(标注合成样本的集合，然后在潜在空间中训练监督分类器)有局限性(需要对目标属性以及相应的手动注释进行清晰的定义),所以👇
2. 方法
    - 分析GAN学习的内部表示，研究将潜在代码带入GAN生成器的`全连接层`的本质作用，以`无监督`方式，揭示潜在的variation factors。
    - 提出了一种通用`封闭形式因式分解`方法**SeFa**，用于`无监督`下的潜在`语义发现`。
3. 实验结果-预览
    - 实现快速和高效（1秒内）
    - 与现有的`无/有监督`方法相比，SeFa在语义识别的`准确`、`多样性`、`解耦性`、`泛化性`方面表现良好。
        
    - 下图是一些操作实例。对于每组图像，中间一个是原始样本，而左边和右边是SeFa`把潜在代码可解释方向进行前/后移动`得到的样本。
        - 泛化性好：SeFa`无监督`地从不同类型GAN中，发现`通用(Versatile)语义`。
            + 不同类型GAN：PGGAN、StyleGAN、BigGAN、StyleGAN2 等多个GAN模型，它们分别是在不同的数据集上训练的。
            + 无监督：即使不知道图像中对象的底层3D模型/姿态标签，SeFa也可以对它们旋转。
        ![figure1](https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qXWQdJhMUgvIIia1x5ibcVLopgE5QDjicNar5CxBcOeY99Jz8Y5gXZlE9Z4vME4KKo9FaOQib7K3kA/640)

    


### 本文方法：SeFa
1. GAN生成过程-回顾
    - 生成过程是$I = G(z)$，其中$ I ⊆ R^{H×W×C}，z⊆ R^d $，Z是输入潜在空间，I是输出图像。
    - 有两种常见的方法将向量z输入生成器，如图2所示。这两种方法都需要由全连接层(FC)实现的线性投影来进行映射。 ![figure2](https://img-1300025586.cos.ap-shanghai.myqcloud.com/figure2.png)
    - 因此，我们将生成过程重新定义为$ I = G'(FC(z)) = G'(y) $。G'表示除了FC之外的生成器剩余部分。
2. 潜在空间和语义的关系
    - 现有的研究表明，GAN的潜在空间，可以用向量`算术属性`编码丰富的语义知识。
    - 这种向量算术特性通常是通过`将潜码向某一方向移动`来实现的。$ z' = z + αn $  其中$n∈R^D$表示`与特定属性对应的方向`，α是移动步长。
    - 所以，输出图像$ I = G'(FC(z')) $中，语义将相应地发生变化。
3. 无监督语义分解
    - 目标：以无监督的方式，找到语义上有意义的方向n。
        + 由$ z' = z + αn $可知，语义实际上是由潜在方向n决定的，它与采样代码z无关。所以，我们要找的是n，而不是z，这样才能在最大程度上使I语义转移。
    - 问题简化
        + 由$ I = G'(FC(z)) = G'(y) $可知，寻找能够导致I的显著变化的方向n。👉假设y的大变化会导致I的大变化。👉`寻找能够导致y的显著变化的方向n`。
    - 建模n和y之间的关系
        + 设$A∈R^{m×d}$和$b∈R^m$分别表示权重和偏置，其中m是投影空间的维数。
        + $ y = FC(z) = Az + b $
        + $ ∆y = FC(z') - FC(z) = (A(z + αn) + b) - (Az + b) = αAn $
        + 全连接层(A)转换起着“语义选择器”的作用。为了使y发生很大的变化，我们需要找到一个方向，使这个方向在A的`投影`之后带来一个大的范数。
        + 通过求解优化问题，将这`投影`分解为探索潜在语义的指导。
            * $ n^∗ = arg \max_{n∈R^d: n^Tn=1} ||An||_2^2 $
            * 设置α=1，并对所有方向使用单位向量(以确保它们是可比较的)
            * 对于探索k个最重要的语义{n1，n2，·，·，nk}，对上面式子加Σ，引入拉格朗日乘子求解。
4. 语义发现的性质
    - (1)发现的所有语义方向${n_i}_{i=1}^k$在潜在空间中都是`正交`的。
        * 所有语义方向都是矩阵$A^TA$的`特征向量`，它是半正定的。所以，有$ A^T A = Q Λ Q^T $成立。
            + 在`k个最重要的语义`求解推导过程中，得出的结论
            + 其中，Λ是对角矩阵，表示特征值。Q是正交矩阵，包含所有特征向量。
    - (2)语义方向不同，FC输出也不同，这种变化∆y也是`正交`的。$ ∆y_i^T ∆y_j = n_i^T A^T A n_j = n_i^T (λ_j n_j) = 0, ∀i ≠ j $
    - 基于以上两点，我们期望${n_i}_{i=1}^k$所对应的语义是相互解耦(disentangled)的。

### 实验
1. 模型和数据
    - 模型：the state-of-the-art GAN models,including PGGAN[15], StyleGAN [16], BigGAN[4], and StyleGAN2[17]
        + 为了对人脸进行定量分析，本文在前人[23]基础上，使用ResNet-50在CelebA数据集上训练了一个属性预测器。
    - 数据：human faces (CelebA-HQ [15] and FF-HQ [16]), anime faces [1], scenes and objects (LSUN [26]), streetscapes [19], and ImageNet [6].
1. 与`无监督`baseline（基于采样、学习两种）的比较            
    - (1)与基于`采样`的无监督方法(先对潜在代码集合采样，执行PCA，找到主要方向)比较
        + 由**表1**可知，本文方法发现的语义方向更`接近ground truth`；且不依赖于采样数据，更稳定。
            * ![table1](https://img-1300025586.cos.ap-shanghai.myqcloud.com/table1.png)
                >表1 语义识别方面，不同方法对比。“Dist.”表示与ground truth之间的余弦距离（越小越好），“No.”表示特征向量下标（从0开始，值越小越好，表示语义方向越重要）。
        + 由**图3**可知，
            * SeFa生成结果(b行)较`准确`，更接近于监督方法 InterFaceGAN(c行)所生成的结果。
            * SeFa`解耦性`好。作为对比，观察到在StyleGAN上用PCA编辑pose时，身份和发型也发生了变化(a行)。
            * ![](https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qXWQdJhMUgvIIia1x5ibcVTdCJVnicF6BI5LF6csOjl8U0l5Tgictjb8utTGdQzQEJlp2WL5uibORcw/640) 
             >图3：与基于采样的无监督方法之间的定性对比。(a)基于采样的无监督方法；(b)SeFa方法；(c)监督方法InterFaceGAN。

    - (2)与基于`学习`的无监督基线info-PGGAN(要求训练前知道语义factor的数量。如果想增加更多语义，就要从头重新训练)的比较
        + 由图4可知，本文方法识别GANs自动学习的语义是`解耦`的，更`准确`。
            * 当使用Info-PGGAN编辑pose时，hair color竟然跟着变化了。
                ![](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qXWQdJhMUgvIIia1x5ibcVrficEzQJjP4ONjsWxxsYX1Rpu42dvkzqtvgu6wGVEkqvGGqic1bDIYLg/640)
                >图4：Info-PGGAN(a)和SeFa(b)发现语义的定性对比。
2. 与`监督`方法的比较、语义性质分析
    - 从`解耦性`和`多样性`的角度，将本文算法与最新的用于潜在语义发现的有监督方法InterFaceGAN进行比较。
    - 解耦性
        + 本文方法发现的语义,表现出与`有监督`方法`相似`的解耦性质。例如，姿势和微笑几乎独立于其他三种属性，而性别、年龄、眼镜则彼此高度相关。见表2 ![](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qXWQdJhMUgvIIia1x5ibcVcec7FpcYeibvKZXvMzibICzNPicX8aRgmRXjHnzLQe7dMic2pyVA5sSxcg/640)
            >表2：通过评估语义得分随潜码调整而发生的变化，对不同方法进行重新评分分析。每一行展示了将潜码朝某个方向移动的结果。
    - 多样性
        + 本文方法可以识别a)更多的语义、以及b)叠加语义，如图5。由于缺乏语义预测器、01属性无法描述叠加语义（复杂发型），InterFaceGAN做不到a),b)两点。
            ![](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qXWQdJhMUgvIIia1x5ibcVeByo622TuHTPjLyu3dz2sAUYZA0bIic4uDuV5yTqdBmt3lEkTka57icg/640)
            >图5
    - 真实图像处理：给定待编辑目标图像，先用GAN将其投影到潜在代码，使用发现的潜在语义来调节，再映射到图像空间里。
3. 泛化性
    - 将Sefa应用于各类的最先进的GAN（StyleGAN、StyleGAN2、Conditional BigGAN，不同数据集上训练），验证了泛化能力。

### 总结
- 为了识别GAN学到的潜在语义，（目标）
- 本文通过研究`全连接层`的本质作用，提出了一种`通用`的`封闭形式因式分解`方法**SeFa**，用于`无监督`下的潜在`语义发现`。（方法）
- 结果表明，与现有的`无/有监督`方法相比，SeFa在语义识别的`准确性`、`多样性`、`解耦性`、`泛化性`方面表现良好。（效果）
